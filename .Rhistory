xts, lubridate, TTR, PerformanceAnalytics, ggplot2, dygraphs, corrplot,
recipes, caret, glmnet)
10^(-5)
# They are models which can handle the multi-collinearity
ridgefit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 0,
lambda = seq(from = 1e6, to = 1, length = 50)))
ridgefit
# They are models which can handle the multi-collinearity
ridgefit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 0,
lambda = seq(from = 1e-6, to = 1, length = 50)))
ridgefit
# They are models which can handle the multi-collinearity
ridgefit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 0,
lambda = seq(from = 1e-6, to = .2, length = 50)))
ridgefit
plot(ridgefit)
# LASSO
lassofit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 1,
lambda = seq(from = 1e-6, to = 1, length = 50)))
plot(lassofit) # lambda: 0.0326539
# LASSO
lassofit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 1,
lambda = seq(from = 1e-6, to = .1, length = 50)))
plot(lassofit) # lambda: 0.0326539
# LASSO
lassofit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 1,
lambda = seq(from = 1e-6, to = .05, length = 50)))
plot(lassofit) # lambda: 0.0326539
# LASSO
lassofit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = 1,
lambda = seq(from = 1e-9, to = .05, length = 50)))
plot(lassofit) # lambda: 0.0326539
lassofit
ridgefit
# ELASTIC NET
elnetfit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = c(0, 1),
lambda = seq(from = 1e-9, to = .1, length = 100)))
plot(elnetfit)
elnetfit
# ELASTIC NET
elnetfit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = c(0, 1),
lambda = .0001))
plot(elnetfit)
# ELASTIC NET
elnetfit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, length = 50),
lambda = seq(from = 1e-6, to = 1,  length = 100)))
plot(elnetfit)
elnetfit
# ELASTIC NET
elnetfit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, length = 50),
lambda = 1e-3))
plot(elnetfit)
elnetfit
# ELASTIC NET
elnetfit <- train(Direction ~ .,
data = train.df_1,
method = "glmnet",
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(alpha = seq(from = 0, to = 1, length = 50),
lambda = 1e-4))
elnetfit
lassofit
ridgefit
ridgefit$modelInfo
ridgefit$finalModel
lasso_model <- lassofit$finalModel
predict(lasso_model)
predict(lasso_model, newx = train.df_1)
predict(lasso_model, newx = train.df_1[, -11])
predict(lasso_model, newx = matrix(train.df_1[, -11]))
matrix(train.df_1[, -11])
as.matrix(train.df_1[, -11])
predict(lasso_model, newx = as.matrix(train.df_1[, -11]))
lasso_model <- glmnet(x = train.df_1[, -11], y = train.df_1[, 11], family = 'binomial',
alpha = 1, lambda = 0.005102042)
train.df_1[, 11]
lasso_model <- glmnet(x = train.df_1[, -11], y = as.integer(train.df_1[, 11]), family = 'binomial',
alpha = 1, lambda = 0.005102042)
lasso_model <- glmnet(x = train.df_1[, -11], y = unlist(train.df_1[, 11]), family = 'binomial',
alpha = 1, lambda = 0.005102042)
lasso_model
ridge_model <- lasso_model <- glmnet(x = train.df_1[, -11], y = unlist(train.df_1[, 11]), family = 'binomial',
alpha = 0, lambda = 0.0326539)
ridge_model
rfFit <- train(Direction ~ .,
data = train.df_1,
method = 'rf',
trControl = trainControl(method = "cv"))
rfFit
rfFit <- train(Direction ~ .,
data = train.df_1,
method = 'rf',
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(mtry = c(2,3,4,5,6,7,8,9,10),
ntree = c(150,250,350,500)))
rfFit <- train(Direction ~ .,
data = train.df_1,
method = 'rf',
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(mtry = c(2,3,4,5,6,7,8,9,10)))
plot(rfFit)
rfFit
table(train.df_1$Direction)
prop.table(table(train.df_1$Direction))
corrplot(
cor(train.df[, -ncol(df)]),
method = 'square',
type = 'full',
order = 'hclust',
tl.col = 'black'
)
corrplot(
cor(train.df[, -ncol(df)]),
method = 'square',
type = 'full',
order = 'hclust',
tl.col = 'black'
)
corrplot(
cor(train.df_1[, -ncol(df)]),
method = 'square',
type = 'full',
order = 'hclust',
tl.col = 'black'
)
summary(train.df_1)
scom_pca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_pca(num_comp = 10, threshold = .95)
step_init <- recipe(Direction ~ ., data = train.df)
scom_pca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_pca(num_comp = 10, threshold = .95)
scom_pca
scom_pca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_pca(all_numeric_predictors(), num_comp = 10, threshold = .95)
scom_pca
# extracting the transformed dataset from the object
pca.ng <- scom_pca |>
prep(training = train.df, retain = TRUE, verbose = TRUE)
juice(pca.ng)
scom_pca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_pca(all_numeric_predictors(), num_comp = 10, threshold = .75)
# extracting the transformed dataset from the object
pca.ng <- scom_pca |>
prep(training = train.df, retain = TRUE, verbose = TRUE)
pca.ng
juice(pca.ng)
scom_pca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_pca(all_numeric_predictors(), num_comp = 10, threshold = .95)
# extracting the transformed dataset from the object
pca.ng <- scom_pca |>
prep(training = train.df, retain = TRUE, verbose = TRUE)
train.df_2 <- juice(pca.ng)
train.df_2
# Constructing the test dataset with the same pre processing steps operated on train data
test.df_2 <- bake(pca.ng, test.df)
test.df_2
train.df_2 |>
ggplot()+
geom_point(aes(x = PC1, y = PC2, col = Direction))+
labs(title = "Principal Components Analysis",
x = "PC-01", y = "PC-02")+
theme_minimal()
glm_model <- glm(Direction ~ ., data = train.df_2,
family = 'binomial')
summary(glm_model)
glmFit <- train(Direction ~ ., data = train.df_2,
method = 'glm',
trControl = trainControl(method = "cv"))
glmFit
glm_model <- glm(Direction ~ ., data = train.df_2,
method = 'binomial')
glm_model <- glm(Direction ~ ., data = train.df_2,
family = 'binomial')
glm_model
glm_model <- glm(Direction ~ ., data = train.df_2,
family = 'binomial') |>
stats::step(direction = 'both')
glm_model
summary(glm_model)
Direction ~ . - PC7
glm_model$terms
glm_model$formula
glmFit <- train(glm_model$formula, data = train.df_2,
method = 'glm',
trControl = trainControl(method = "cv"))
summary(glm_model)
plot(glmFit)
glmFit
sig_range <-
step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
prep(training = train.df, retain = TRUE, verbose = TRUE) |>
juice(all_numeric_predictors()) |>
as.matrix() |>
sigest(frac = 1)
p_load(dplyr, tidyr, readxl, quantmod, ModelMetrics, randomForest, rpart ,rpart.plot,
xts, lubridate, TTR, PerformanceAnalytics, ggplot2, dygraphs, corrplot,
recipes, caret, glmnet, kernlab)
sig_range <-
step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
prep(training = train.df, retain = TRUE, verbose = TRUE) |>
juice(all_numeric_predictors()) |>
as.matrix() |>
sigest(frac = 1)
sig_range
scom_kpca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_kpca(all_numeric_predictors(),
num_comp = 10,
threshold = .95,
options = list(kernel = "rbfdot", kpar = list(sigma = sig_range[2])))
# extracting the transformed dataset from the object
kpca.ng <- scom_kpca |>
prep(training = train.df, retain = TRUE, verbose = TRUE)
rlang::last_trace()
step_init
step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors())
sig_range
sig_range[2]
(kernel = "rbfdot",
list(kernel = "rbfdot",
kpar = list(sigma = sig_range[2]))
scom_kpca <- step_init |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors()) |>
step_YeoJohnson(all_numeric_predictors()) |>
step_kpca(all_numeric_predictors(),
num_comp = 10,
#threshold = .95,
options = list(kernel = "rbfdot",
kpar = list(sigma = sig_range[2])))
# extracting the transformed dataset from the object
kpca.ng <- scom_kpca |>
prep(training = train.df, retain = TRUE, verbose = TRUE)
train.df_3 <- juice(kpca.ng)
train.df_3
train.df_2 |>
ggplot()+
geom_point(aes(x = kPC01, y = kPC02, col = Direction))+
labs(title = "Kernel Principal Components Analysis",
x = "kPC-01", y = "kPC-02")+
theme_minimal()
train.df_3 |>
ggplot()+
geom_point(aes(x = kPC01, y = kPC02, col = Direction))+
labs(title = "Kernel Principal Components Analysis",
x = "kPC-01", y = "kPC-02")+
theme_minimal()
# Constructing the test dataset
test.df_3 <- bake(kpca.ng, test.df)
glm_model_pca <- glm(Direction ~ ., data = train.df_2,
family = 'binomial') |>
stats::step(direction = 'both')
glm_model_kpca <- glm(Direction ~ ., data = train.df_3,
family = 'binomial') |>
stats::step(direction = 'both')
summary(glm_model_pca)
summary(glm_model_kpca)
glmFit.pca <- train(glm_model_pca$formula, data = train.df_2,
method = 'glm',
trControl = trainControl(method = "cv"))
glmFit.pca
glmFit.kpca <- train(glm_model_kpca$formula, data = train.df_3,
method = 'glm',
trControl = trainControl(method = "cv"))
glmFit.kpca
glm_model_kpca <- glm(Direction ~ ., data = train.df_3,
family = 'binomial')
summary(glm_model_kpca)
kpca.ng
(kpca.ng$steps)
kpca_eigen <- unname(eig((kpca.ng$steps)[[3]][[5]])) |>
data.frame() |>
setNames("kpca_eigen") |>
mutate(
component = 1:ncol(kpca_features),
component_contribution = kpca_eigen / sum(kpca_eigen),
group_contribution = cumsum(component_contribution)
) |>
setNames(c("Eigen", "component", "component_contribution", "group_contribution"))
(eig((kpca.ng$steps)[[3]][[5]]))
((kpca.ng$steps)[[3]][[5]])
(kpca.ng$steps)[[3]]
(kpca.ng$steps)[[1]]
(kpca.ng$steps)[[2]]
(kpca.ng$steps)[[3]]
(kpca.ng$steps)[[4]]
(eig((kpca.ng$steps)[[4]][[5]]))
kpca_eigen <- unname(eig((kpca.ng$steps)[[4]][[5]])) |>
data.frame() |>
setNames("kpca_eigen") |>
mutate(
component = 1:ncol(kpca_features),
component_contribution = kpca_eigen / sum(kpca_eigen),
group_contribution = cumsum(component_contribution)
) |>
setNames(c("Eigen", "component", "component_contribution", "group_contribution"))
kpca_eigen <- unname(eig((kpca.ng$steps)[[4]][[5]])) |>
data.frame() |>
setNames("kpca_eigen") |>
mutate(
component = 1:10,
component_contribution = kpca_eigen / sum(kpca_eigen),
group_contribution = cumsum(component_contribution)
) |>
setNames(c("Eigen", "component", "component_contribution", "group_contribution"))
View(kpca_eigen)
glm_model_pca$formula
glm_model_kpca <- glm(Direction ~ Direction ~ kPC01 + kPC02 + kPC03 + kPC04 +
kPC05 + kPC06 + kPC07 + kPC08,
data = train.df_3,
family = 'binomial') |>
stats::step(direction = 'both')
glm_model_kpca <- glm(Direction ~ kPC01 + kPC02 + kPC03 + kPC04 +
kPC05 + kPC06 + kPC07 + kPC08,
data = train.df_3,
family = 'binomial') |>
stats::step(direction = 'both')
summary(glm_model_pca)
summary(glm_model_kpca)
glm_model_pca <- glm(Direction ~ ., data = train.df_2,
family = 'binomial') |>
stats::step(direction = 'both')
glm_model_pca
glm_model_kpca <- glm(Direction ~ kPC01 + kPC02 + kPC03 + kPC04 +
kPC05 + kPC06 + kPC07 + kPC08,
data = train.df_3,
family = 'binomial')
glm_model_kpca
summary(glm_model_kpca)
glm_model_kpca <- glm(Direction ~ kPC01 + kPC02 + kPC03 + kPC04 +
kPC05 + kPC06,
data = train.df_3,
family = 'binomial')
summary(glm_model_pca)
summary(glm_model_kpca)
glm_model_kpca <- glm(Direction ~ kPC01 + kPC02 + kPC03 + kPC04 +
kPC05 + kPC06 + kPC07 + kPC08,
data = train.df_3,
family = 'binomial') |>
stats::step(direction = 'both')
summary(glm_model_pca)
summary(glm_model_kpca)
glmFit.pca <- train(glm_model_pca$formula, data = train.df_2,
method = 'glm',
trControl = trainControl(method = "cv"))
glmFit.pca
glmFit.kpca <- train(glm_model_kpca$formula, data = train.df_3,
method = 'glm',
trControl = trainControl(method = "cv"))
glmFit.kpca
svmFit <- train(Direction ~ .,
data = train.df_2,
method = "svmRadial",
tuneLength = 5,
trControl = trainControl(method = "cv"),
scaled = FALSE)
svmFit.pca <- train(Direction ~ .,
data = train.df_2,
method = "svmRadial",
tuneLength = 5,
trControl = trainControl(method = "cv"),
scaled = FALSE)
svmFit.pca
sig_range
?ksvm
svmFit.pca <- train(Direction ~ .,
data = train.df_2,
method = "svmRadial",
tuneLength = 5,
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(C = seq(from = .1, to = 10, length = 10)),
scaled = FALSE)
svmFit.pca <- train(Direction ~ .,
data = train.df_2,
method = "svmRadial",
tuneLength = 5,
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(sigma = sig_range,
C = seq(from = .1, to = 10, length = 10)),
scaled = FALSE)
svmFit.pca
kpca_eigen
svmFit.kpca <- train(Direction ~ .,
data = train.df_3,
method = "svmRadial",
tuneLength = 5,
trControl = trainControl(method = "cv"),
tuneGrid = expand.grid(sigma = sig_range,
C = seq(from = .1, to = 10, length = 10)),
scaled = FALSE)
svmFit.kpca
train.df_3
predict(ridge_model, test.df)
test.df
predict(ridge_model, test.df_1)
test.df_1
predict(ridge_model, test.df_1[, 1:10])
predict(ridge_model, as.matrix(test.df_1[, 1:10]))
predict(ridge_model, as.matrix(test.df_1[, 1:10]),type = 'response')
rpred = predict(ridge_model, as.matrix(test.df_1[, 1:10]),type = 'response')
confusionMatrix
?confusionMatrix
ModelMetrics::confusionMatrix(actual = test.df_1$Direction,
predicted = rpred,
cutoff = .5)
ModelMetrics::confusionMatrix(actual = test.df_1$Direction,
predicted = rpred,
cutoff = .6)
ModelMetrics::confusionMatrix(actual = test.df_1$Direction,
predicted = rpred,
cutoff = .8)
table(test.df_1$Direction)
summary(rpred)
ModelMetrics::confusionMatrix(actual = test.df_1$Direction,
predicted = rpred,
cutoff = .4)
rval <- ifelse(rpred < .5, 'Down', 'Up') |> factor()
caret::confusionMatrix(test.df_1$Direction,
predicted = rval)
caret::confusionMatrix(reference = test.df_1$Direction,
predicted = rval)
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .6, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .4, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .54, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .5, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .6, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
rval <- ifelse(rpred < .55, 'Down', 'Up') |> factor()
caret::confusionMatrix(reference = test.df_1$Direction,
data = rval)
cat("\\noindent\\rule{\\textwidth}{0.4pt}\n")
